import{_ as o,j as e,o as t,g as c,k as a,h as l,Q as p,s as n}from"./chunks/framework.e0c66c3f.js";const D=JSON.parse('{"title":"Filebeat 简介 ","description":"","frontmatter":{},"headers":[],"relativePath":"posts/devops/042_大数据运维实战/(3087) 第16讲：轻量级日志收集工具 Filebeat 应用案例.md","filePath":"posts/devops/042_大数据运维实战/(3087) 第16讲：轻量级日志收集工具 Filebeat 应用案例.md","lastUpdated":1696338709000}'),r={name:"posts/devops/042_大数据运维实战/(3087) 第16讲：轻量级日志收集工具 Filebeat 应用案例.md"},E=p("",4),y=p("",14),i=p("",25),u=n("p",null,"可以看到，Filebeat 已经将收集到的数据传到了 Redis 服务器上。",-1),F=n("h3",{id:"总结",tabindex:"-1"},[l("总结 "),n("a",{class:"header-anchor",href:"#总结","aria-label":'Permalink to "总结"'},"​")],-1),q=n("p",null,"本课时主要讲解了 Filebeat 的安装、配置及如何使用。在经典的 EFK 架构中，Filebeat 经常作为前端收集日志，然后将日志传给 Kafka，然后 Logstash 再从 Kafka 消费日志中将数据发送到 Elasticsearch 中，最后在 Kibana 中进行可视化展示。在后面的课时内容中我将陆续介绍这些架构的实现细节。",-1);function d(b,g,h,A,f,C){const s=e("Image");return t(),c("div",null,[E,a(s,{alt:"image1.png",src:"https://s0.lgstatic.com/i/image/M00/22/B4/Ciqc1F7saKKAQ8YZAAEBev585Hk521.png"}),y,a(s,{alt:"01.png",src:"https://s0.lgstatic.com/i/image/M00/22/B5/Ciqc1F7sakCAZRRhAAVtPJ5WfBg187.png"}),l(),a(s,{alt:"02.png",src:"https://s0.lgstatic.com/i/image/M00/22/B5/Ciqc1F7sakqAYIedAAU0BudFkBA057.png"}),l(),a(s,{alt:"03.png",src:"https://s0.lgstatic.com/i/image/M00/22/C1/CgqCHl7salKAH_SMAAb9p7oShcE030.png"}),i,a(s,{alt:"image2.png",src:"https://s0.lgstatic.com/i/image/M00/22/B6/Ciqc1F7saviAIgKIAACKia52tP0739.png"}),u,F,q])}const m=o(r,[["render",d]]);export{D as __pageData,m as default};
