import{_ as p,j as a,o as e,g as l,k as n,h as s,s as t,Q as _}from"./chunks/framework.b3d8e22e.js";const Z=JSON.parse('{"title":"为什么扛不住相同用户百万的流量 ","description":"","frontmatter":{},"headers":[],"relativePath":"posts/backEnd/23讲搞定后台架构实战_文档/(6131) 06  如何应对热点数据的查询？.md","filePath":"posts/backEnd/23讲搞定后台架构实战_文档/(6131) 06  如何应对热点数据的查询？.md","lastUpdated":1696417798000}'),i={name:"posts/backEnd/23讲搞定后台架构实战_文档/(6131) 06  如何应对热点数据的查询？.md"},c=t("p",null,'在"04 讲和 05 讲"里，我们介绍了基于 Binlog 实现的全量缓存的读服务，以及如何实现一个低延迟、可扩展的同步架构。通过这两讲的学习，你可以构建出一个无毛刺且平均性能在 100ms 以内的读接口。对缓存进行分布式部署后，抗住秒级百万的 QPS 毫无压力。不管是在面试还是在实战中，关于"如何架构一个高性能的读服务"，我相信你都能够轻松应对。',-1),r=t("p",null,'但上述的"百万 QPS"有一个非常重要的限制条件，即这百万的 QPS 都是分属于不同用户的。我们先不讨论是否可能，试想一下如果这百万 QPS 都属于同一个用户，系统还扛得住吗？',-1),g=t("p",null,"如果采用前两讲的架构，必然抗扛不住的！因此本讲将站在一个全新的视角，带你分析此架构待改善的方向，并探寻新的架构优化方案来应对百万 QPS的流量。",-1),h=t("h3",{id:"为什么扛不住相同用户百万的流量",tabindex:"-1"},[s("为什么扛不住相同用户百万的流量 "),t("a",{class:"header-anchor",href:"#为什么扛不住相同用户百万的流量","aria-label":'Permalink to "为什么扛不住相同用户百万的流量"'},"​")],-1),d=t("p",null,"当百万的 QPS 属于不同用户时，因缓存是集群化的，所有到达业务后台的请求会根据一定路由规则（如 Hash），分散到请求缓存集群中的某一个节点，具体架构如下图 1 所示：",-1),u=t("p",null,"图 1：百万请求属于不同用户的架构图",-1),m=t("p",null,"假设一个节点最大能够支撑 10W QPS，我们只需要在集群中部署 10 台节点即可支持百万流量。但当百万 QPS 都属于同一用户时，即使缓存是集群化的，同一个用户的请求都会被路由至集群中的某一个节点，整体架构如图 2 所示：",-1),A=_("",9),P=_("",9),C=_("",10),S=t("p",null,"图 5：前置缓存实时更新方案图",-1),q=t("p",null,"通过异构前置缓存用作判断，可以过滤出需要处理的数据，并实时调用对应机器更新即可。此方案实现起来较复杂且异构本来也导致了延迟，实际上大部分场景设置刷新时间即可满足。",-1),T=t("p",null,[t("strong",null,"再者要把控好瞬间的逃逸流量")],-1),Q=t("p",null,"应用初始化时，前置缓存是空的。假设在初始化时，瞬间出现热点查询，所有的热点请求都会逃逸到后端缓存里。可能这个瞬间热点就会把后端缓存打挂。",-1),b=t("p",null,"其次，如果前置缓存采用定期过期，在过期时若将数据清理掉，那么所有的请求都会逃逸至后端加载最新的缓存，也有可能把后端缓存打挂。这两种情况对应的流程图如下图 6 所示：",-1),f=t("p",null,"图 6：逃逸流量的架构图",-1),k=t("p",null,"对于这两种情况，可以对逃逸流量进行前置等待或使用历史数据的方案。不管是初始化还是数据过期，在从后端加载数据时，只允许一个请求逃逸。这样最大的逃逸流量为部署的应用总数，量级可控。架构如下图 7 所示：",-1),M=t("p",null,"图 7：逃逸流量控制的架构图",-1),N=t("p",null,"对于数据初始化为空时，其他非逃逸的请求可以等待前置缓存的数据并设置一个超时时间。对于数据过期需要更新时，并不主动清理掉数据。其他非逃逸请求使用历史脏数据，而逃逸的那一个请求负责把数据取回来并刷新前置缓存。",-1),V=t("p",null,[t("strong",null,"最后如何发现热点缓存并前置")],-1),x=t("p",null,"除了需要应对热点缓存，另外一个重点就是如何发现热点缓存。对于发现热点有两个方式，一种是被动发现，另外一种是主动发现。",-1),E=t("p",null,"被动发现是借助前置缓存有容量上限实现的。在被动发现的方案里，读服务接受到的所有请求都会默认从前置缓存中获取数据，如不存在，则从缓存服务器进行加载。因为前置缓存的容量淘汰策略是 LRU，如果数据是热点，它的访问次数一定非常高，因此它一定会在前置缓存中。借助前置缓存的容量上限和淘汰策略，即实现了热点发现。",-1),I=t("p",null,"但此方式也存在一个问题------所有的请求都优先从前置缓存获取数据，并在未查询到时加载服务端数据到本地的前置缓存里，此方式也会把非热点数据存储至前置缓存里，导致非热点数据产生非必要的延迟性。",-1),H=t("p",null,"主动发现则需要借助一些外部计数工具来实现热点的发现。外部计数工具的思路大体比较类似，都是在一个集中的位置对于请求进行计数，并根据配置的阈值判断某请求是否会命中数据。对于判定为热点的数据，主动的推送至应用内的前置缓存即可。下图 8 为在缓存服务器进行计数的架构方案：",-1),U=t("p",null,"图 8：主动发现热点缓存架构图",-1),G=t("p",null,"采用主动发现的架构后，读服务接受到请求后仍然会默认的从前置缓存获取数据，如获取到即直接返回。如未获取到，会穿透去查询后端缓存的数据并直接返回。但穿透获取到的数据并不会写入本地前置缓存。数据是否为热点且是否要写入前置缓存，均由计数工具来决定。此方案很好地解决了因误判断带来的延迟问题。",-1),D=t("h3",{id:"降级兜底不可少",tabindex:"-1"},[s("降级兜底不可少 "),t("a",{class:"header-anchor",href:"#降级兜底不可少","aria-label":'Permalink to "降级兜底不可少"'},"​")],-1),K=t("p",null,"在采用了前置缓存并解决了上述四大类问题之后，当你再次遇到百万级并发时，基本没什么疑难问题了。但这里还存在一个前置条件，即当热点查询发生时，你所部署的容器数量所能支撑的 QPS 要大于热点查询的 QPS。",-1),L=t("p",null,"但实际情况并非如此，你所部署的机器能够支持的 QPS 未必都能够大于当次的热点查询。对于可能出现的超预期流量，可以使用前置限流的策略进行应对。在系统上线前，对于开启了前置缓存的应用进行压测，得到单机最大的 QPS。根据压测值设置单机的限流阈值，阈值可以设置为压测值的一半或者更低。设置为压测阈值的一半或更低，是因为压测时应用 CPU 基本已达到 100%，为了保证线上应用能够正常运转，是不能让 CPU 达到 100% 的。架构如下图 9 所示：",-1),R=_("",8);function B(J,j,v,$,y,z){const o=a("Image");return e(),l("div",null,[c,r,g,h,d,n(o,{alt:"图片1.png",src:"https://s0.lgstatic.com/i/image/M00/90/5E/CgqCHmAKucqAbboHAAG3HqmbdA4265.png"}),s(),u,m,n(o,{alt:"图片2.png",src:"https://s0.lgstatic.com/i/image/M00/90/53/Ciqc1GAKudmAHmzrAAGksJjhJzU880.png"}),s(),A,n(o,{alt:"图片3.png",src:"https://s0.lgstatic.com/i/image/M00/90/5E/CgqCHmAKueyAGN66AAJjLMmDZ6k094.png"}),s(),P,n(o,{alt:"图片4.png",src:"https://s0.lgstatic.com/i/image/M00/90/5E/CgqCHmAKujGAPMLxAAIdo7D9VQg203.png"}),s(),C,n(o,{alt:"图片5.png",src:"https://s0.lgstatic.com/i/image/M00/90/53/Ciqc1GAKukyATLIcAALPLt4aBHQ469.png"}),s(),S,q,T,Q,b,n(o,{alt:"图片6.png",src:"https://s0.lgstatic.com/i/image/M00/90/53/Ciqc1GAKumCAUk7AAAGURQds17U123.png"}),s(),f,k,n(o,{alt:"图片7.png",src:"https://s0.lgstatic.com/i/image/M00/90/5E/CgqCHmAKum6AaeatAAGZsV88_qU074.png"}),s(),M,N,V,x,E,I,H,n(o,{alt:"图片8.png",src:"https://s0.lgstatic.com/i/image/M00/90/5E/CgqCHmAKuoSAThmMAAJkfL8HMiQ678.png"}),s(),U,G,D,K,L,n(o,{alt:"图片9.png",src:"https://s0.lgstatic.com/i/image/M00/90/53/Ciqc1GAKupOACvfqAAH7UdfXtdI473.png"}),s(),R])}const W=p(i,[["render",B]]);export{Z as __pageData,W as default};
