import{_ as p,j as o,o as t,g as r,k as n,h as e,Q as l,s}from"./chunks/framework.e0c66c3f.js";const N=JSON.parse('{"title":"Spring WebFlux 的应用场景 ","description":"","frontmatter":{},"headers":[],"relativePath":"posts/backEnd/Spring 响应式编程实战_文档/(6991) 09  框架升级：WebFlux 比 Web MVC 到底好在哪里？.md","filePath":"posts/backEnd/Spring 响应式编程实战_文档/(6991) 09  框架升级：WebFlux 比 Web MVC 到底好在哪里？.md","lastUpdated":1696338709000}'),c={name:"posts/backEnd/Spring 响应式编程实战_文档/(6991) 09  框架升级：WebFlux 比 Web MVC 到底好在哪里？.md"},i=l("",10),E=l("",11),d=l("",15),y=s("p",null,"图 3 Spring WebFlux 整体架构图",-1),b=s("p",null,"请注意，在处理 HTTP 请求上，我们需要使用支持异步非阻塞的响应式服务器引擎，常见的包括 Netty、Undertow 以及支持 Servlet 3.1 及以上版本的 Servlet 容器。",-1),u=s("h3",{id:"对比-webflux-和-webmvc-的处理模型",tabindex:"-1"},[e("对比 WebFlux 和 WebMVC 的处理模型 "),s("a",{class:"header-anchor",href:"#对比-webflux-和-webmvc-的处理模型","aria-label":'Permalink to "对比 WebFlux 和 WebMVC 的处理模型"'},"​")],-1),g=s("p",null,"现在我们已经明确了 WebMVC 到 WebFlux 的演进过程，但你可能会问，新的 WebFlux 要比传统 WebMVC 好在哪里呢？从两者的处理模型上入手可以帮助你很好地理解这个问题，我们一起来看一下。",-1),h=s("h4",{id:"webflux-和-web-mvc-中的处理模型",tabindex:"-1"},[e("WebFlux 和 Web MVC 中的处理模型 "),s("a",{class:"header-anchor",href:"#webflux-和-web-mvc-中的处理模型","aria-label":'Permalink to "WebFlux 和 Web MVC 中的处理模型"'},"​")],-1),_=s("p",null,"通过前面的讨论你已经知道 Servlet 是阻塞式的，所以 WebMVC 建立在阻塞 I/O 之上，我们来分析这种模型下线程处理请求的过程。假设有一个工作线程会处理来自客户端的请求，所有请求构成一个请求队列，并由一个线程按顺序进行处理。针对一个请求，线程需要执行两部分工作，首先是接受请求，然后再对其进行处理，如下图所示。",-1),F=s("p",null,"图 4 同步阻塞式处理过程",-1),v=s("p",null,[e("在前面的示例中，正如你可能注意到的，工作线程的实际处理时间远小于花费在阻塞操作上的时间。这意味着工作线程会被 I/O 读取或写入数据这一操作所阻塞。从这个简单的图中，"),s("strong",null,"我们可以得出结论，线程效率低下"),e("。同时，因为所有请求是排队的，相当于一个请求队列，所以接受请求和处理请求这两部分操作实际上是可以共享等待时间的。")],-1),W=s("p",null,"相比之下，WebFlux 构建在非阻塞 API 之上，这意味着没有操作需要与 I/O 阻塞线程进行交互。接受和处理请求的效率很高，如下图所示。",-1),C=s("p",null,"图 5 异步非阻塞式处理过程",-1),x=s("p",null,"将上图中所展示的异步非阻塞请求处理与前面的阻塞过程进行比较，我们会注意到，现在没有在读取请求数据时发生等待，工作线程高效接受新连接。然后，提供了非阻塞 I/O 机制的底层操作系统会告诉我们请求数据是否已经接收完成，并且处理器可以在不阻塞的情况下进行处理。",-1),S=s("p",null,"类似的，写入响应结果时同样不需要阻塞，操作系统会在准备好将一部分数据非阻塞地写入 I/O 时通知我们。这样，我们就拥有了最佳的 CPU 利用率。",-1),A=s("p",null,"前面的示例展示了 WebFlux 比 WebMVC 更有效地利用一个工作线程，因此可以在相同的时间内处理更多的请求。那么，如果是在多线程的场景下会发生什么呢？我们来看下面这张图。",-1),M=s("p",null,"图 6 多线程处理过程示意图",-1),m=s("p",null,"从上图中可以看出，多线程模型允许更快地处理排队请求，能够同时接受、处理和响应几乎相同数量的请求。当然，我们明白多线程技术有利有弊。当处理用户请求涉及太多的线程实例时，相互之间就需要协调资源，这是由于它们之间的不一致性会导致性能下降。",-1),H=s("h4",{id:"处理模型对性能的影响",tabindex:"-1"},[e("处理模型对性能的影响 "),s("a",{class:"header-anchor",href:"#处理模型对性能的影响","aria-label":'Permalink to "处理模型对性能的影响"'},"​")],-1),V=s("p",null,"讲到这里，你可能会问，不同的处理模型对性能会有多大程度的影响呢？这里我们就引用维护Spring 框架的 Pivotal 公司软件开发主管 Biju Kunjummen 的测试结果来对这一问题进行解答。",-1),f=s("p",null,"在 Biju Kunjummen 的测试用例中，他分别基于 WebMVC 所提供的阻塞式 RestTemplate 以及 WebFlux 所提供的非阻塞式 WebClient 工具类对远程 Web 服务发起请求。对于不同组的并发用户（300、1000、1500、3000、5000），他分别发送了一个 delay 属性设置为 300 ms 的请求，每个用户重复该场景 30 次，请求之间的延迟为 1 到 2 秒。测试用例中使用了 Gatling 这款工具来执行压测。",-1),R=s("p",null,"这里我们截取 300 和 3000 并发用户场景下的结果进行对比，如下面两张图所示。",-1),D=s("p",null,"图 7 300 并发用户下的测试结果",-1),q=l("",7);function k(w,B,T,j,P,I){const a=o("Image");return t(),r("div",null,[i,n(a,{alt:"Drawing 0.png",src:"https://s0.lgstatic.com/i/image6/M01/2C/90/Cgp9HWBlYNSAQ_6xAABLuhAav9c145.png"}),e(),E,n(a,{alt:"Drawing 1.png",src:"https://s0.lgstatic.com/i/image6/M00/2C/98/CioPOWBlYOGAF_ssAACxp3BYjUM960.png"}),e(),d,n(a,{alt:"Drawing 2.png",src:"https://s0.lgstatic.com/i/image6/M01/2C/90/Cgp9HWBlYO6AE2c_AABMFtMZQAU060.png"}),e(),y,b,u,g,h,_,n(a,{alt:"Drawing 3.png",src:"https://s0.lgstatic.com/i/image6/M00/2C/90/Cgp9HWBlYPeAePjYAABQR4znOfo927.png"}),e(),F,v,W,n(a,{alt:"Drawing 4.png",src:"https://s0.lgstatic.com/i/image6/M00/2C/98/CioPOWBlYQSAV2szAACULiV9Rbo555.png"}),e(),C,x,S,A,n(a,{alt:"Drawing 5.png",src:"https://s0.lgstatic.com/i/image6/M00/2C/90/Cgp9HWBlYQuAMuj3AABd75iFsms666.png"}),e(),M,m,H,V,f,R,n(a,{alt:"Drawing 6.png",src:"https://s0.lgstatic.com/i/image6/M00/2C/90/Cgp9HWBlYRSAUYUoAAK7ajk3HpQ553.png"}),e(),D,n(a,{alt:"Drawing 7.png",src:"https://s0.lgstatic.com/i/image6/M00/2C/98/CioPOWBlYRuAQxDNAAK5Dq13-Eg742.png"}),e(),q])}const Y=p(c,[["render",k]]);export{N as __pageData,Y as default};
