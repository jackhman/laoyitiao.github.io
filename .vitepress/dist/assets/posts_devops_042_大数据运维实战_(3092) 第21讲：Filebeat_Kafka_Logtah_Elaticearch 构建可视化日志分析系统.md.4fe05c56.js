import{_ as s,o as a,g as n,Q as l}from"./chunks/framework.f949202b.js";const g=JSON.parse('{"title":"典型 ELK 应用架构 ","description":"","frontmatter":{},"headers":[],"relativePath":"posts/devops/042_大数据运维实战/(3092) 第21讲：Filebeat+Kafka+Logtah+Elaticearch 构建可视化日志分析系统.md","filePath":"posts/devops/042_大数据运维实战/(3092) 第21讲：Filebeat+Kafka+Logtah+Elaticearch 构建可视化日志分析系统.md","lastUpdated":null}'),p={name:"posts/devops/042_大数据运维实战/(3092) 第21讲：Filebeat+Kafka+Logtah+Elaticearch 构建可视化日志分析系统.md"},o=l(`<h3 id="典型-elk-应用架构" tabindex="-1">典型 ELK 应用架构 <a class="header-anchor" href="#典型-elk-应用架构" aria-label="Permalink to &quot;典型 ELK 应用架构&quot;">​</a></h3><p>下图是本课时即将要介绍的一个线上真实案例的架构图：</p><p><img src="https://s0.lgstatic.com/i/image/M00/2D/3D/CgqCHl8C6QSAFcJrAAEUqK2v4nw728.png" alt="Drawing 0.png"></p><p>某个线上案例图</p><p>此架构稍微有些复杂，这里解读一下架构图，该图从左到右，总共分为 5 层，每层实现的功能和含义介绍如下。</p><p><strong>第一层，数据采集层</strong>：数据采集层位于最左边的业务服务器集群上，在每个业务服务器上面安装了 Filebeat 做日志收集，然后把采集到的原始日志发送到 Kafka+ZooKeeper 集群上。</p><p><strong>第二层，消息队列层</strong>：原始日志发送到 Kafka+ZooKeeper 集群上后，会进行集中存储，此时，Filbeat 是消息的生产者，存储的消息可以随时被消费。</p><p><strong>第三层，数据分析层</strong>：Logstash 作为消费者，会去 Kafka+ZooKeeper 集群节点实时拉取原始日志，然后将获取到的原始日志根据规则进行分析、清洗、过滤，最后将清洗好的日志转发至 Elasticsearch 集群中。</p><p><strong>第四层，数据持久化存储</strong>：Elasticsearch 集群在接收到 Logstash 发送过来的数据后，执行写磁盘、建索引库等操作，最后将结构化的数据存储到 Elasticsearch 集群上。</p><p><strong>第五层，数据查询、展示层</strong>：Kibana 是一个可视化的数据展示平台，当有数据检索请求时，它从 Elasticsearch 集群上读取数据，然后进行可视化出图和多维度分析。</p><h3 id="部署环境与角色说明" tabindex="-1">部署环境与角色说明 <a class="header-anchor" href="#部署环境与角色说明" aria-label="Permalink to &quot;部署环境与角色说明&quot;">​</a></h3><h4 id="_1-服务器环境与角色" tabindex="-1">1. 服务器环境与角色 <a class="header-anchor" href="#_1-服务器环境与角色" aria-label="Permalink to &quot;1. 服务器环境与角色&quot;">​</a></h4><p>操作系统统一采用 Centos 7.7 版本，各个服务器角色如下表所示：</p><table><thead><tr><th><strong>IP 地址</strong></th><th style="text-align:center;"><strong>主机名</strong></th><th><strong>角色</strong></th><th style="text-align:center;"><strong>用途</strong></th></tr></thead><tbody><tr><td>172.16.213.156</td><td style="text-align:center;">filebeatserver</td><td>业务服务器 + filebeat</td><td style="text-align:center;">业务服务器集群</td></tr><tr><td>172.16.213.31</td><td style="text-align:center;">kafkazk1</td><td>Kafka + ZooKeeper</td><td style="text-align:center;">Kafka Broker 集群</td></tr><tr><td>172.16.213.41</td><td style="text-align:center;">kafkazk2</td><td>Kafka + ZooKeeper</td><td style="text-align:center;"></td></tr><tr><td>172.16.213.70</td><td style="text-align:center;">kafkazk3</td><td>Kafka + ZooKeeper</td><td style="text-align:center;"></td></tr><tr><td>172.16.213.151</td><td style="text-align:center;">logstashserver</td><td>Logstash</td><td style="text-align:center;">数据转发</td></tr><tr><td>172.16.213.152</td><td style="text-align:center;">server1</td><td>ES Master、ES NataNode</td><td style="text-align:center;">Elasticsearch 集群</td></tr><tr><td>172.16.213.138</td><td style="text-align:center;">server2</td><td>ES Master、Kibana</td><td style="text-align:center;"></td></tr><tr><td>172.16.213.80</td><td style="text-align:center;">server3</td><td>ES Master、ES NataNode</td><td style="text-align:center;"></td></tr></tbody></table><p>基本架构图如下：</p><p><img src="https://s0.lgstatic.com/i/image/M00/2D/3D/CgqCHl8C6TOABlahAADXH7tLpRw715.png" alt="Drawing 1.png"></p><p>此架构需要 8 台服务器完成，每台服务器的作用和对应的 IP 信息都已经在图上进行了标注。最前面的一台是 Nginx 服务器，用于产生日志，然后由 Filebeat 来收集 Nginx 产生的日志，Filebeat 将收集到的日志推送（push）到 Kafka 集群中，完成日志的收集工作。接着，Logstash 去 Kafka 集群中拉取（pull）日志并进行日志过滤、分析，之后将日志发送到 Elasticsearch 集群中进行索引和存储，最后由 Kibana 完成日志的可视化查询。</p><p>在下面的介绍中，我们设定 Kafka 集群和 Elasticsearch 集群已经部署完成，在此基础上介绍如何通过 Filebeat 和 Logstash 收集与处理 Nginx 日志。</p><h4 id="_2-软件环境与版本" tabindex="-1">2. 软件环境与版本 <a class="header-anchor" href="#_2-软件环境与版本" aria-label="Permalink to &quot;2. 软件环境与版本&quot;">​</a></h4><p>下表详细说明了本课时安装软件对应的名称和版本号，其中，ELK 三款软件推荐选择一样的版本，这里选择的是 7.7.1 版本。</p><table><thead><tr><th><strong>软件名称</strong></th><th style="text-align:center;"><strong>版本</strong></th><th><strong>说明</strong></th></tr></thead><tbody><tr><td>JDK</td><td style="text-align:center;">JDK 1.8.0_171</td><td>Java 环境解析器</td></tr><tr><td>filebeat</td><td style="text-align:center;">filebeat-7.7.1-linux-x86_64</td><td>前端日志收集器</td></tr><tr><td>Logstash</td><td style="text-align:center;">logstash-7.7.1</td><td>日志收集、过滤、转发</td></tr><tr><td>zookeeper</td><td style="text-align:center;">zookeeper-3.5.8</td><td>资源调度、协作</td></tr><tr><td>Kafka</td><td style="text-align:center;">kafka_2.11-2.4.1</td><td>消息通信中间件</td></tr><tr><td>elasticsearch</td><td style="text-align:center;">elasticsearch-7.7.1</td><td>日志存储与检索</td></tr><tr><td>kibana</td><td style="text-align:center;">kibana-7.7.1-linux-x86_64</td><td>日志展示、分析</td></tr></tbody></table><p>注意，Elasticsearch 新版本中已经自带了 JDK，因此无需用我们指定的 JDK，除此之外，Kafka、ZooKeeper 及 Logstash 都需要 JDK 环境。</p><h3 id="eflk-收集-nginx-访问日志案例" tabindex="-1">EFLK 收集 Nginx 访问日志案例 <a class="header-anchor" href="#eflk-收集-nginx-访问日志案例" aria-label="Permalink to &quot;EFLK 收集 Nginx 访问日志案例&quot;">​</a></h3><h4 id="_1-nginx-日志内容与格式分析" tabindex="-1">1. Nginx 日志内容与格式分析 <a class="header-anchor" href="#_1-nginx-日志内容与格式分析" aria-label="Permalink to &quot;1. Nginx 日志内容与格式分析&quot;">​</a></h4><p>下面是一个业务系统输出的日志格式，由于业务系统输出的日志格式无法更改，因此需要我们通过 Logstash 的 Filter 过滤功能以及 grok 插件来获取需要的数据格式。此业务系统输出的日志内容以及原始格式如下：</p><div class="language-java vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">java</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#79B8FF;">2020</span><span style="color:#F97583;">-</span><span style="color:#79B8FF;">06</span><span style="color:#F97583;">-</span><span style="color:#E1E4E8;">29T00</span><span style="color:#F97583;">:</span><span style="color:#79B8FF;">00</span><span style="color:#F97583;">:</span><span style="color:#79B8FF;">06</span><span style="color:#F97583;">+</span><span style="color:#E1E4E8;">08</span><span style="color:#F97583;">:</span><span style="color:#79B8FF;">00</span><span style="color:#F97583;">|~|</span><span style="color:#79B8FF;">183.61</span><span style="color:#E1E4E8;">.</span><span style="color:#FDAEB7;font-style:italic;">6</span><span style="color:#E1E4E8;">.</span><span style="color:#FDAEB7;font-style:italic;">82</span><span style="color:#F97583;">|~|</span><span style="color:#E1E4E8;">Mozilla</span><span style="color:#F97583;">/</span><span style="color:#79B8FF;">5.0</span><span style="color:#E1E4E8;"> (iPhone; CPU iPhone OS </span><span style="color:#79B8FF;">12_3_1</span><span style="color:#E1E4E8;"> like Mac OS X)AppleWebKit</span><span style="color:#F97583;">/</span><span style="color:#79B8FF;">605.1</span><span style="color:#E1E4E8;">.</span><span style="color:#FDAEB7;font-style:italic;">15</span><span style="color:#E1E4E8;"> (KHTML, like Gecko) Mobile</span><span style="color:#F97583;">/</span><span style="color:#79B8FF;">15E148</span><span style="color:#F97583;">|~|</span><span style="color:#E1E4E8;">http</span><span style="color:#F97583;">:</span><span style="color:#6A737D;">//m.sina.cn/cm/ads_ck_wap.html|~|1460709836200|~|DF0184266887D0E</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#005CC5;">2020</span><span style="color:#D73A49;">-</span><span style="color:#005CC5;">06</span><span style="color:#D73A49;">-</span><span style="color:#24292E;">29T00</span><span style="color:#D73A49;">:</span><span style="color:#005CC5;">00</span><span style="color:#D73A49;">:</span><span style="color:#005CC5;">06</span><span style="color:#D73A49;">+</span><span style="color:#24292E;">08</span><span style="color:#D73A49;">:</span><span style="color:#005CC5;">00</span><span style="color:#D73A49;">|~|</span><span style="color:#005CC5;">183.61</span><span style="color:#24292E;">.</span><span style="color:#B31D28;font-style:italic;">6</span><span style="color:#24292E;">.</span><span style="color:#B31D28;font-style:italic;">82</span><span style="color:#D73A49;">|~|</span><span style="color:#24292E;">Mozilla</span><span style="color:#D73A49;">/</span><span style="color:#005CC5;">5.0</span><span style="color:#24292E;"> (iPhone; CPU iPhone OS </span><span style="color:#005CC5;">12_3_1</span><span style="color:#24292E;"> like Mac OS X)AppleWebKit</span><span style="color:#D73A49;">/</span><span style="color:#005CC5;">605.1</span><span style="color:#24292E;">.</span><span style="color:#B31D28;font-style:italic;">15</span><span style="color:#24292E;"> (KHTML, like Gecko) Mobile</span><span style="color:#D73A49;">/</span><span style="color:#005CC5;">15E148</span><span style="color:#D73A49;">|~|</span><span style="color:#24292E;">http</span><span style="color:#D73A49;">:</span><span style="color:#6A737D;">//m.sina.cn/cm/ads_ck_wap.html|~|1460709836200|~|DF0184266887D0E</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p>可以看出，这段日志都是以&quot;|~|&quot;为区间进行分隔的，那么刚好我们就以&quot;|~|&quot;为区间分隔符，将这段日志内容分割为 6 个字段。这里通过 grok 插件进行正则匹配组合就能完成这个功能。</p><p>完整的 grok 正则匹配组合语句如下：</p><div class="language-java vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">java</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#F97583;">%</span><span style="color:#E1E4E8;">{TIMESTAMP_ISO8601</span><span style="color:#F97583;">:</span><span style="color:#E1E4E8;">localtime}\\</span><span style="color:#F97583;">|</span><span style="color:#E1E4E8;">\\</span><span style="color:#F97583;">~</span><span style="color:#E1E4E8;">\\</span><span style="color:#F97583;">|%</span><span style="color:#E1E4E8;">{IPORHOST</span><span style="color:#F97583;">:</span><span style="color:#E1E4E8;">clientip}\\</span><span style="color:#F97583;">|</span><span style="color:#E1E4E8;">\\</span><span style="color:#F97583;">~</span><span style="color:#E1E4E8;">\\</span><span style="color:#F97583;">|</span><span style="color:#E1E4E8;">(</span><span style="color:#F97583;">%</span><span style="color:#E1E4E8;">{GREEDYDATA</span><span style="color:#F97583;">:</span><span style="color:#E1E4E8;">http_user_agent})\\</span><span style="color:#F97583;">|</span><span style="color:#E1E4E8;">\\</span><span style="color:#F97583;">~</span><span style="color:#E1E4E8;">\\</span><span style="color:#F97583;">|</span><span style="color:#E1E4E8;">(</span><span style="color:#F97583;">%</span><span style="color:#E1E4E8;">{DATA</span><span style="color:#F97583;">:</span><span style="color:#E1E4E8;">http_referer})\\</span><span style="color:#F97583;">|</span><span style="color:#E1E4E8;">\\</span><span style="color:#F97583;">~</span><span style="color:#E1E4E8;">\\</span><span style="color:#F97583;">|%</span><span style="color:#E1E4E8;">{GREEDYDATA</span><span style="color:#F97583;">:</span><span style="color:#E1E4E8;">media_id}\\</span><span style="color:#F97583;">|</span><span style="color:#E1E4E8;">\\</span><span style="color:#F97583;">~</span><span style="color:#E1E4E8;">\\</span><span style="color:#F97583;">|%</span><span style="color:#E1E4E8;">{GREEDYDATA</span><span style="color:#F97583;">:</span><span style="color:#E1E4E8;">nginx_id}</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#D73A49;">%</span><span style="color:#24292E;">{TIMESTAMP_ISO8601</span><span style="color:#D73A49;">:</span><span style="color:#24292E;">localtime}\\</span><span style="color:#D73A49;">|</span><span style="color:#24292E;">\\</span><span style="color:#D73A49;">~</span><span style="color:#24292E;">\\</span><span style="color:#D73A49;">|%</span><span style="color:#24292E;">{IPORHOST</span><span style="color:#D73A49;">:</span><span style="color:#24292E;">clientip}\\</span><span style="color:#D73A49;">|</span><span style="color:#24292E;">\\</span><span style="color:#D73A49;">~</span><span style="color:#24292E;">\\</span><span style="color:#D73A49;">|</span><span style="color:#24292E;">(</span><span style="color:#D73A49;">%</span><span style="color:#24292E;">{GREEDYDATA</span><span style="color:#D73A49;">:</span><span style="color:#24292E;">http_user_agent})\\</span><span style="color:#D73A49;">|</span><span style="color:#24292E;">\\</span><span style="color:#D73A49;">~</span><span style="color:#24292E;">\\</span><span style="color:#D73A49;">|</span><span style="color:#24292E;">(</span><span style="color:#D73A49;">%</span><span style="color:#24292E;">{DATA</span><span style="color:#D73A49;">:</span><span style="color:#24292E;">http_referer})\\</span><span style="color:#D73A49;">|</span><span style="color:#24292E;">\\</span><span style="color:#D73A49;">~</span><span style="color:#24292E;">\\</span><span style="color:#D73A49;">|%</span><span style="color:#24292E;">{GREEDYDATA</span><span style="color:#D73A49;">:</span><span style="color:#24292E;">media_id}\\</span><span style="color:#D73A49;">|</span><span style="color:#24292E;">\\</span><span style="color:#D73A49;">~</span><span style="color:#24292E;">\\</span><span style="color:#D73A49;">|%</span><span style="color:#24292E;">{GREEDYDATA</span><span style="color:#D73A49;">:</span><span style="color:#24292E;">nginx_id}</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p>这里用到了四种匹配模式，即 TIMESTAMP_ISO8601、IPORHOST、GREEDYDATA 和 DATA，都是 Logstash 默认的，可以在 Logstash 安装目录下找到。具体含义可自行查阅，这里不再介绍。</p><p>编写 grok 正则匹配组合语句有一定难度，需要根据具体的日志格式和 Logstash 提供的匹配模式配合实现，不我们可以<a href="http://grokdebug.herokuapp.com" target="_blank" rel="noreferrer">借助于 grok 调试平台</a>，在这个平台上，可以很方便地调试 grok 正则表达式。</p><p>有了上面这个 grok 匹配规则之后，就可以将此规则写入 Logstash 配置文件中，稍后我们来看看如何在 Logstash 中配置日志字段分割。</p><h4 id="_2-配置-filebeat" tabindex="-1">2. 配置 Filebeat <a class="header-anchor" href="#_2-配置-filebeat" aria-label="Permalink to &quot;2. 配置 Filebeat&quot;">​</a></h4><p>Filebeat 是安装在 Nginx 服务器上的，关于 Filebeat 的安装与基础应用，在前面已经详细介绍过了，这里不再说明，仅给出配置好的 filebeat.yml 文件的内容：</p><div class="language-java vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">java</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#E1E4E8;">filebeat.inputs</span><span style="color:#F97583;">:</span></span>
<span class="line"><span style="color:#F97583;">-</span><span style="color:#E1E4E8;"> type</span><span style="color:#F97583;">:</span><span style="color:#E1E4E8;"> log</span></span>
<span class="line"><span style="color:#E1E4E8;">  enabled</span><span style="color:#F97583;">:</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">true</span></span>
<span class="line"><span style="color:#E1E4E8;">  paths</span><span style="color:#F97583;">:</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#F97583;">-</span><span style="color:#E1E4E8;"> </span><span style="color:#F97583;">/</span><span style="color:#E1E4E8;">data</span><span style="color:#F97583;">/</span><span style="color:#E1E4E8;">nginx</span><span style="color:#F97583;">/</span><span style="color:#E1E4E8;">openresty</span><span style="color:#F97583;">/</span><span style="color:#E1E4E8;">logs</span><span style="color:#F97583;">/</span><span style="color:#E1E4E8;">nginxlogs_</span><span style="color:#F97583;">*</span><span style="color:#E1E4E8;">.log</span></span>
<span class="line"><span style="color:#E1E4E8;">  fields</span><span style="color:#F97583;">:</span></span>
<span class="line"><span style="color:#E1E4E8;">   log_topic</span><span style="color:#F97583;">:</span><span style="color:#E1E4E8;"> nginxlogs</span></span>
<span class="line"><span style="color:#E1E4E8;">filebeat.config.modules</span><span style="color:#F97583;">:</span></span>
<span class="line"><span style="color:#E1E4E8;">  path</span><span style="color:#F97583;">:</span><span style="color:#E1E4E8;"> \${path.config}</span><span style="color:#F97583;">/</span><span style="color:#E1E4E8;">modules.d</span><span style="color:#6A737D;">/*.yml</span></span>
<span class="line"><span style="color:#6A737D;">  reload.enabled: false</span></span>
<span class="line"><span style="color:#6A737D;">setup.template.settings:</span></span>
<span class="line"><span style="color:#6A737D;">  index.number_of_shards: 1</span></span>
<span class="line"><span style="color:#6A737D;">name: &quot;172.16.213.156&quot;</span></span>
<span class="line"><span style="color:#6A737D;">setup.kibana:</span></span>
<span class="line"><span style="color:#6A737D;">output.kafka:</span></span>
<span class="line"><span style="color:#6A737D;">  enabled: true</span></span>
<span class="line"><span style="color:#6A737D;">  hosts: [&quot;172.16.213.31:9092&quot;, &quot;172.16.213.41:9092&quot;, &quot;172.16.213.70:9092&quot;]</span></span>
<span class="line"><span style="color:#6A737D;">  version: &quot;0.10&quot;</span></span>
<span class="line"><span style="color:#6A737D;">  topic: &#39;%{[fields][log_topic]}&#39;</span></span>
<span class="line"><span style="color:#6A737D;">  codec.format.string: &#39;%{[message]}&#39;</span></span>
<span class="line"><span style="color:#6A737D;">  partition.round_robin:</span></span>
<span class="line"><span style="color:#6A737D;">    reachable_only: true</span></span>
<span class="line"><span style="color:#6A737D;">  worker: 2</span></span>
<span class="line"><span style="color:#6A737D;">  required_acks: 1</span></span>
<span class="line"><span style="color:#6A737D;">  compression: gzip</span></span>
<span class="line"><span style="color:#6A737D;">  max_message_bytes: 10000000</span></span>
<span class="line"><span style="color:#6A737D;">processors:</span></span>
<span class="line"><span style="color:#6A737D;"> - drop_fields:</span></span>
<span class="line"><span style="color:#6A737D;">    fields: [&quot;input&quot;, &quot;host&quot;, &quot;agent.type&quot;, &quot;agent.ephemeral_id&quot;, &quot;agent.id&quot;, &quot;agent.version&quot;, &quot;ecs&quot;]</span></span>
<span class="line"><span style="color:#6A737D;">logging.level: info</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292E;">filebeat.inputs</span><span style="color:#D73A49;">:</span></span>
<span class="line"><span style="color:#D73A49;">-</span><span style="color:#24292E;"> type</span><span style="color:#D73A49;">:</span><span style="color:#24292E;"> log</span></span>
<span class="line"><span style="color:#24292E;">  enabled</span><span style="color:#D73A49;">:</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">true</span></span>
<span class="line"><span style="color:#24292E;">  paths</span><span style="color:#D73A49;">:</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">-</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">/</span><span style="color:#24292E;">data</span><span style="color:#D73A49;">/</span><span style="color:#24292E;">nginx</span><span style="color:#D73A49;">/</span><span style="color:#24292E;">openresty</span><span style="color:#D73A49;">/</span><span style="color:#24292E;">logs</span><span style="color:#D73A49;">/</span><span style="color:#24292E;">nginxlogs_</span><span style="color:#D73A49;">*</span><span style="color:#24292E;">.log</span></span>
<span class="line"><span style="color:#24292E;">  fields</span><span style="color:#D73A49;">:</span></span>
<span class="line"><span style="color:#24292E;">   log_topic</span><span style="color:#D73A49;">:</span><span style="color:#24292E;"> nginxlogs</span></span>
<span class="line"><span style="color:#24292E;">filebeat.config.modules</span><span style="color:#D73A49;">:</span></span>
<span class="line"><span style="color:#24292E;">  path</span><span style="color:#D73A49;">:</span><span style="color:#24292E;"> \${path.config}</span><span style="color:#D73A49;">/</span><span style="color:#24292E;">modules.d</span><span style="color:#6A737D;">/*.yml</span></span>
<span class="line"><span style="color:#6A737D;">  reload.enabled: false</span></span>
<span class="line"><span style="color:#6A737D;">setup.template.settings:</span></span>
<span class="line"><span style="color:#6A737D;">  index.number_of_shards: 1</span></span>
<span class="line"><span style="color:#6A737D;">name: &quot;172.16.213.156&quot;</span></span>
<span class="line"><span style="color:#6A737D;">setup.kibana:</span></span>
<span class="line"><span style="color:#6A737D;">output.kafka:</span></span>
<span class="line"><span style="color:#6A737D;">  enabled: true</span></span>
<span class="line"><span style="color:#6A737D;">  hosts: [&quot;172.16.213.31:9092&quot;, &quot;172.16.213.41:9092&quot;, &quot;172.16.213.70:9092&quot;]</span></span>
<span class="line"><span style="color:#6A737D;">  version: &quot;0.10&quot;</span></span>
<span class="line"><span style="color:#6A737D;">  topic: &#39;%{[fields][log_topic]}&#39;</span></span>
<span class="line"><span style="color:#6A737D;">  codec.format.string: &#39;%{[message]}&#39;</span></span>
<span class="line"><span style="color:#6A737D;">  partition.round_robin:</span></span>
<span class="line"><span style="color:#6A737D;">    reachable_only: true</span></span>
<span class="line"><span style="color:#6A737D;">  worker: 2</span></span>
<span class="line"><span style="color:#6A737D;">  required_acks: 1</span></span>
<span class="line"><span style="color:#6A737D;">  compression: gzip</span></span>
<span class="line"><span style="color:#6A737D;">  max_message_bytes: 10000000</span></span>
<span class="line"><span style="color:#6A737D;">processors:</span></span>
<span class="line"><span style="color:#6A737D;"> - drop_fields:</span></span>
<span class="line"><span style="color:#6A737D;">    fields: [&quot;input&quot;, &quot;host&quot;, &quot;agent.type&quot;, &quot;agent.ephemeral_id&quot;, &quot;agent.id&quot;, &quot;agent.version&quot;, &quot;ecs&quot;]</span></span>
<span class="line"><span style="color:#6A737D;">logging.level: info</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br></div></div><p>在这个配置文件中，是将 Nginx 的访问日志 /data/nginx/openresty/logs/nginxlogs_*.log 内容实时地发送到 Kafka 集群 Topic 为 nginxlogs 中。需要注意的是 Filebeat 输出日志到 Kafka 中配置文件的写法。这里用了 codec.format.string 配置项，也就是将日志保持原样输出到 Kafka 中，这种方式对后面的日志过滤减轻了很多工作量。</p><p>配置完成后，启动 Filebeat 即可：</p><div class="language-java vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">java</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#E1E4E8;">[root@</span><span style="color:#F97583;">filebeatserver</span><span style="color:#E1E4E8;"> </span><span style="color:#F97583;">~</span><span style="color:#E1E4E8;">]# cd </span><span style="color:#F97583;">/</span><span style="color:#E1E4E8;">usr</span><span style="color:#F97583;">/</span><span style="color:#E1E4E8;">local</span><span style="color:#F97583;">/</span><span style="color:#E1E4E8;">filebeat</span></span>
<span class="line"><span style="color:#E1E4E8;">[root@</span><span style="color:#F97583;">filebeatserver</span><span style="color:#E1E4E8;">  filebeat]# nohup  .</span><span style="color:#F97583;">/</span><span style="color:#E1E4E8;">filebeat </span><span style="color:#F97583;">-</span><span style="color:#E1E4E8;">e </span><span style="color:#F97583;">-</span><span style="color:#E1E4E8;">c filebeat.yml </span><span style="color:#F97583;">&amp;</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292E;">[root@</span><span style="color:#D73A49;">filebeatserver</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">~</span><span style="color:#24292E;">]# cd </span><span style="color:#D73A49;">/</span><span style="color:#24292E;">usr</span><span style="color:#D73A49;">/</span><span style="color:#24292E;">local</span><span style="color:#D73A49;">/</span><span style="color:#24292E;">filebeat</span></span>
<span class="line"><span style="color:#24292E;">[root@</span><span style="color:#D73A49;">filebeatserver</span><span style="color:#24292E;">  filebeat]# nohup  .</span><span style="color:#D73A49;">/</span><span style="color:#24292E;">filebeat </span><span style="color:#D73A49;">-</span><span style="color:#24292E;">e </span><span style="color:#D73A49;">-</span><span style="color:#24292E;">c filebeat.yml </span><span style="color:#D73A49;">&amp;</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>启动完成后，可查看 Filebeat 的启动日志，观察启动是否正常。注意，通过 nohup 这种方式启动 Filebeat 后，若要退出 SecureCRT 的话，则需要输入 exit 命令正常退出，不然 Filebeat 进程会自动关闭。</p><h4 id="_3-配置-logstash" tabindex="-1">3. 配置 Logstash <a class="header-anchor" href="#_3-配置-logstash" aria-label="Permalink to &quot;3. 配置 Logstash&quot;">​</a></h4><p>上面我已经对 Nginx 的日志格式进行了分析，并做好了匹配规则，下面直接给出 Logstash 事件配置文件 kafka_nginx_into_es.conf 的内容：</p><div class="language-java vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">java</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#E1E4E8;">input {</span></span>
<span class="line"><span style="color:#E1E4E8;">        kafka {</span></span>
<span class="line"><span style="color:#E1E4E8;">        bootstrap_servers </span><span style="color:#F97583;">=&gt;</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">&quot;172.16.213.31:9092,172.16.213.41:9092,172.16.213.70:9092&quot;</span><span style="color:#E1E4E8;"> </span></span>
<span class="line"><span style="color:#E1E4E8;">        topics </span><span style="color:#F97583;">=&gt;</span><span style="color:#E1E4E8;"> [</span><span style="color:#9ECBFF;">&quot;nginxlogs&quot;</span><span style="color:#E1E4E8;">]</span></span>
<span class="line"><span style="color:#E1E4E8;">        add_field </span><span style="color:#F97583;">=&gt;</span><span style="color:#E1E4E8;"> { </span><span style="color:#9ECBFF;">&quot;[@metadata][myid]&quot;</span><span style="color:#E1E4E8;"> </span><span style="color:#F97583;">=&gt;</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">&quot;nginxlogs&quot;</span><span style="color:#E1E4E8;"> }</span></span>
<span class="line"><span style="color:#E1E4E8;">        } </span></span>
<span class="line"><span style="color:#E1E4E8;">}</span></span>
<span class="line"><span style="color:#E1E4E8;">filter {</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#F97583;">if</span><span style="color:#E1E4E8;"> [@</span><span style="color:#F97583;">metadata</span><span style="color:#E1E4E8;">][myid] </span><span style="color:#F97583;">==</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">&quot;nginxlogs&quot;</span><span style="color:#E1E4E8;"> {</span></span>
<span class="line"><span style="color:#E1E4E8;">        grok {</span></span>
<span class="line"><span style="color:#E1E4E8;">              match </span><span style="color:#F97583;">=&gt;</span><span style="color:#E1E4E8;"> { </span><span style="color:#9ECBFF;">&quot;message&quot;</span><span style="color:#E1E4E8;"> </span><span style="color:#F97583;">=&gt;</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">&quot;%{TIMESTAMP_ISO8601:localtime}</span><span style="color:#79B8FF;">\\|\\~\\|</span><span style="color:#9ECBFF;">%{IPORHOST:clientip}</span><span style="color:#79B8FF;">\\|\\~\\|</span><span style="color:#9ECBFF;">(%{GREEDYDATA:http_user_agent})</span><span style="color:#79B8FF;">\\|\\~\\|</span><span style="color:#9ECBFF;">(%{DATA:http_referer})</span><span style="color:#79B8FF;">\\|\\~\\|</span><span style="color:#9ECBFF;">%{GREEDYDATA:media_id}</span><span style="color:#79B8FF;">\\|\\~\\|</span><span style="color:#9ECBFF;">%{GREEDYDATA:nginx_id}&quot;</span><span style="color:#E1E4E8;"> }</span></span>
<span class="line"><span style="color:#E1E4E8;">        }</span></span>
<span class="line"><span style="color:#E1E4E8;">        date {</span></span>
<span class="line"><span style="color:#E1E4E8;">            match </span><span style="color:#F97583;">=&gt;</span><span style="color:#E1E4E8;"> [</span><span style="color:#9ECBFF;">&quot;localtime&quot;</span><span style="color:#E1E4E8;">, </span><span style="color:#9ECBFF;">&quot;yyyy-MM-dd&#39;T&#39;HH:mm:ssZZ&quot;</span><span style="color:#E1E4E8;">]</span></span>
<span class="line"><span style="color:#E1E4E8;">            target </span><span style="color:#F97583;">=&gt;</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">&quot;@timestamp&quot;</span></span>
<span class="line"><span style="color:#E1E4E8;">        }</span></span>
<span class="line"><span style="color:#E1E4E8;">       </span></span>
<span class="line"><span style="color:#E1E4E8;">        mutate {  </span></span>
<span class="line"><span style="color:#E1E4E8;">           remove_field </span><span style="color:#F97583;">=&gt;</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">&quot;@version&quot;</span><span style="color:#E1E4E8;">      </span></span>
<span class="line"><span style="color:#E1E4E8;">           remove_field </span><span style="color:#F97583;">=&gt;</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">&quot;message&quot;</span></span>
<span class="line"><span style="color:#E1E4E8;">remove_field </span><span style="color:#F97583;">=&gt;</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">&quot;localtime&quot;</span></span>
<span class="line"><span style="color:#E1E4E8;">        }  </span></span>
<span class="line"><span style="color:#E1E4E8;">    }</span></span>
<span class="line"><span style="color:#E1E4E8;">}</span></span>
<span class="line"><span style="color:#E1E4E8;">output { </span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#F97583;">if</span><span style="color:#E1E4E8;"> [@</span><span style="color:#F97583;">metadata</span><span style="color:#E1E4E8;">][myid] </span><span style="color:#F97583;">==</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">&quot;nginxlogs&quot;</span><span style="color:#E1E4E8;"> {</span></span>
<span class="line"><span style="color:#E1E4E8;">        elasticsearch {</span></span>
<span class="line"><span style="color:#E1E4E8;">        hosts </span><span style="color:#F97583;">=&gt;</span><span style="color:#E1E4E8;"> [</span><span style="color:#9ECBFF;">&quot;172.16.213.152:9200&quot;</span><span style="color:#E1E4E8;">,</span><span style="color:#9ECBFF;">&quot;172.16.213.138:9200&quot;</span><span style="color:#E1E4E8;">,</span><span style="color:#9ECBFF;">&quot;172.16.213.80:9200&quot;</span><span style="color:#E1E4E8;">]</span></span>
<span class="line"><span style="color:#E1E4E8;">        index </span><span style="color:#F97583;">=&gt;</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">&quot;nginxlogs-%{+YYYY.MM.dd}&quot;</span></span>
<span class="line"><span style="color:#E1E4E8;">        } </span></span>
<span class="line"><span style="color:#E1E4E8;">  }</span></span>
<span class="line"><span style="color:#E1E4E8;">}</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292E;">input {</span></span>
<span class="line"><span style="color:#24292E;">        kafka {</span></span>
<span class="line"><span style="color:#24292E;">        bootstrap_servers </span><span style="color:#D73A49;">=&gt;</span><span style="color:#24292E;"> </span><span style="color:#032F62;">&quot;172.16.213.31:9092,172.16.213.41:9092,172.16.213.70:9092&quot;</span><span style="color:#24292E;"> </span></span>
<span class="line"><span style="color:#24292E;">        topics </span><span style="color:#D73A49;">=&gt;</span><span style="color:#24292E;"> [</span><span style="color:#032F62;">&quot;nginxlogs&quot;</span><span style="color:#24292E;">]</span></span>
<span class="line"><span style="color:#24292E;">        add_field </span><span style="color:#D73A49;">=&gt;</span><span style="color:#24292E;"> { </span><span style="color:#032F62;">&quot;[@metadata][myid]&quot;</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">=&gt;</span><span style="color:#24292E;"> </span><span style="color:#032F62;">&quot;nginxlogs&quot;</span><span style="color:#24292E;"> }</span></span>
<span class="line"><span style="color:#24292E;">        } </span></span>
<span class="line"><span style="color:#24292E;">}</span></span>
<span class="line"><span style="color:#24292E;">filter {</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">if</span><span style="color:#24292E;"> [@</span><span style="color:#D73A49;">metadata</span><span style="color:#24292E;">][myid] </span><span style="color:#D73A49;">==</span><span style="color:#24292E;"> </span><span style="color:#032F62;">&quot;nginxlogs&quot;</span><span style="color:#24292E;"> {</span></span>
<span class="line"><span style="color:#24292E;">        grok {</span></span>
<span class="line"><span style="color:#24292E;">              match </span><span style="color:#D73A49;">=&gt;</span><span style="color:#24292E;"> { </span><span style="color:#032F62;">&quot;message&quot;</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">=&gt;</span><span style="color:#24292E;"> </span><span style="color:#032F62;">&quot;%{TIMESTAMP_ISO8601:localtime}</span><span style="color:#005CC5;">\\|\\~\\|</span><span style="color:#032F62;">%{IPORHOST:clientip}</span><span style="color:#005CC5;">\\|\\~\\|</span><span style="color:#032F62;">(%{GREEDYDATA:http_user_agent})</span><span style="color:#005CC5;">\\|\\~\\|</span><span style="color:#032F62;">(%{DATA:http_referer})</span><span style="color:#005CC5;">\\|\\~\\|</span><span style="color:#032F62;">%{GREEDYDATA:media_id}</span><span style="color:#005CC5;">\\|\\~\\|</span><span style="color:#032F62;">%{GREEDYDATA:nginx_id}&quot;</span><span style="color:#24292E;"> }</span></span>
<span class="line"><span style="color:#24292E;">        }</span></span>
<span class="line"><span style="color:#24292E;">        date {</span></span>
<span class="line"><span style="color:#24292E;">            match </span><span style="color:#D73A49;">=&gt;</span><span style="color:#24292E;"> [</span><span style="color:#032F62;">&quot;localtime&quot;</span><span style="color:#24292E;">, </span><span style="color:#032F62;">&quot;yyyy-MM-dd&#39;T&#39;HH:mm:ssZZ&quot;</span><span style="color:#24292E;">]</span></span>
<span class="line"><span style="color:#24292E;">            target </span><span style="color:#D73A49;">=&gt;</span><span style="color:#24292E;"> </span><span style="color:#032F62;">&quot;@timestamp&quot;</span></span>
<span class="line"><span style="color:#24292E;">        }</span></span>
<span class="line"><span style="color:#24292E;">       </span></span>
<span class="line"><span style="color:#24292E;">        mutate {  </span></span>
<span class="line"><span style="color:#24292E;">           remove_field </span><span style="color:#D73A49;">=&gt;</span><span style="color:#24292E;"> </span><span style="color:#032F62;">&quot;@version&quot;</span><span style="color:#24292E;">      </span></span>
<span class="line"><span style="color:#24292E;">           remove_field </span><span style="color:#D73A49;">=&gt;</span><span style="color:#24292E;"> </span><span style="color:#032F62;">&quot;message&quot;</span></span>
<span class="line"><span style="color:#24292E;">remove_field </span><span style="color:#D73A49;">=&gt;</span><span style="color:#24292E;"> </span><span style="color:#032F62;">&quot;localtime&quot;</span></span>
<span class="line"><span style="color:#24292E;">        }  </span></span>
<span class="line"><span style="color:#24292E;">    }</span></span>
<span class="line"><span style="color:#24292E;">}</span></span>
<span class="line"><span style="color:#24292E;">output { </span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#D73A49;">if</span><span style="color:#24292E;"> [@</span><span style="color:#D73A49;">metadata</span><span style="color:#24292E;">][myid] </span><span style="color:#D73A49;">==</span><span style="color:#24292E;"> </span><span style="color:#032F62;">&quot;nginxlogs&quot;</span><span style="color:#24292E;"> {</span></span>
<span class="line"><span style="color:#24292E;">        elasticsearch {</span></span>
<span class="line"><span style="color:#24292E;">        hosts </span><span style="color:#D73A49;">=&gt;</span><span style="color:#24292E;"> [</span><span style="color:#032F62;">&quot;172.16.213.152:9200&quot;</span><span style="color:#24292E;">,</span><span style="color:#032F62;">&quot;172.16.213.138:9200&quot;</span><span style="color:#24292E;">,</span><span style="color:#032F62;">&quot;172.16.213.80:9200&quot;</span><span style="color:#24292E;">]</span></span>
<span class="line"><span style="color:#24292E;">        index </span><span style="color:#D73A49;">=&gt;</span><span style="color:#24292E;"> </span><span style="color:#032F62;">&quot;nginxlogs-%{+YYYY.MM.dd}&quot;</span></span>
<span class="line"><span style="color:#24292E;">        } </span></span>
<span class="line"><span style="color:#24292E;">  }</span></span>
<span class="line"><span style="color:#24292E;">}</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br></div></div><p>这个配置文件完成实现的功能有如下几个方面：</p><ul><li><p>从 Kafka 接收输入数据（消费数据）</p></li><li><p>将输入日志内容分为 6 个字段</p></li><li><p>将输入日志的时间字段信息转存到 @timestamp 字段里</p></li><li><p>删除 @version 字段、message 字段和 localtime 字段</p></li><li><p>将过滤分割后的内容输出到 Elasticsearch 中</p></li></ul><p>在此配置文件中，input 中的 topics 用来指定从 Kafka 中需要从哪个 Topic 中读取数据，add_field 用来增加一个字段，用于标识和判断，在 output 输出中会用到。</p><p>接着，需要注意一下 date 插件中 match 的写法，其中，localtime 是输入日志中的时间字段，&quot;yyyy-MM-dd&#39;T&#39;HH:mm:ssZZ&quot; 用来匹配输入日志字段的格式，在匹配成功后，会将 localtime 字段的内容转存到 @timestamp 字段里，target 默认指的就是 @timestamp。所以 &quot;target =&gt; &quot;@timestamp&quot;&quot; 表示用 localtime 字段的时间更新 @timestamp 字段的时间。</p><p>在最后的 output 配置段中，使用了 Elasticsearch 插件，其中，hosts 是一个数组类型的值，后面跟的值是 Elasticsearch 节点的地址与端口，默认端口是 9200，可添加多个地址。index 指定 Nginx 日志在 Elasticsearch 中索引的名称，该名称会在 Kibana 中用到。这个索引名 nginxlogs 可以使用变量，Logstash 提供了 %{+YYYY.MM.dd} 这种写法。在语法解析的时候，看到以 + 开头的，就会自动认为后面是时间格式，尝试用时间格式来解析后续字符串。</p><p>这种以天为单位分割的写法，可以很容易删除老的数据或者搜索指定时间范围内的数据。此外，注意索引名中不能有大写字母。这里的索引名称我定义以 nginxlogs 开头，后面跟上时间，这样会每天生成一个索引。</p><p>所有配置完成后，就可以启动 logstash 了，执行如下命令：</p><div class="language-java vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">java</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#E1E4E8;">[root@</span><span style="color:#F97583;">logstashserver</span><span style="color:#E1E4E8;"> </span><span style="color:#F97583;">~</span><span style="color:#E1E4E8;">]# cd </span><span style="color:#F97583;">/</span><span style="color:#E1E4E8;">usr</span><span style="color:#F97583;">/</span><span style="color:#E1E4E8;">local</span><span style="color:#F97583;">/</span><span style="color:#E1E4E8;">logstash</span></span>
<span class="line"><span style="color:#E1E4E8;">[root@</span><span style="color:#F97583;">logstashserver</span><span style="color:#E1E4E8;"> logstash]# nohup bin</span><span style="color:#F97583;">/</span><span style="color:#E1E4E8;">logstash </span><span style="color:#F97583;">-</span><span style="color:#E1E4E8;">f kafka_nginx_into_es.conf </span><span style="color:#F97583;">&amp;</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292E;">[root@</span><span style="color:#D73A49;">logstashserver</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">~</span><span style="color:#24292E;">]# cd </span><span style="color:#D73A49;">/</span><span style="color:#24292E;">usr</span><span style="color:#D73A49;">/</span><span style="color:#24292E;">local</span><span style="color:#D73A49;">/</span><span style="color:#24292E;">logstash</span></span>
<span class="line"><span style="color:#24292E;">[root@</span><span style="color:#D73A49;">logstashserver</span><span style="color:#24292E;"> logstash]# nohup bin</span><span style="color:#D73A49;">/</span><span style="color:#24292E;">logstash </span><span style="color:#D73A49;">-</span><span style="color:#24292E;">f kafka_nginx_into_es.conf </span><span style="color:#D73A49;">&amp;</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>logstash 启动后，可以通过查看 logstash 日志来观察是否启动正常，如果启动失败，则会在日志中有启动失败的提示。</p><h4 id="_4-安装与配置-kibana" tabindex="-1">4. 安装与配置 Kibana <a class="header-anchor" href="#_4-安装与配置-kibana" aria-label="Permalink to &quot;4. 安装与配置 Kibana&quot;">​</a></h4><p>前面课时中我陆续介绍了 Filebeat、Logstash、Elasticsearch 的安装、配置与使用，而在经典的 EFLK 架构（Elasticsearch、Filebeat、Logstash、Kibana）中，还有一个软件------Kibana，此软件负责数据的展示与多维度查询。下面我就介绍下这个软件的使用。</p><p><strong>（1）下载与安装 Kibana</strong></p><p>Kibana 使用 JavaScript 语言编写，安装部署十分简单，即下即用，你可以<a href="https://www.elastic.co/cn/downloads/kibana" target="_blank" rel="noreferrer">从 Elastic 官网</a>下载所需的版本，需要注意的是 Kibana 与 Elasticsearch 的版本必须一致。另外，在安装 Kibana 时，要确保 Elasticsearch、Logstash 和 Kafka 已经安装完毕。</p><p>这里安装的版本是 kibana-7.7.1-linux-x86_64.tar.gz。将下载下来的安装包直接解压到一个路径下即可完成 Kibana 的安装，这里将其安装到 server1 主机（172.16.213.152）上，然后统一将 Kibana 安装到 /usr/local 目录下，基本操作过程如下：</p><div class="language-dart vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">dart</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#E1E4E8;">[root</span><span style="color:#F97583;">@server</span><span style="color:#E1E4E8;">1 </span><span style="color:#F97583;">~</span><span style="color:#E1E4E8;">]# tar </span><span style="color:#F97583;">-</span><span style="color:#E1E4E8;">zxvf kibana</span><span style="color:#F97583;">-</span><span style="color:#79B8FF;">7.7</span><span style="color:#E1E4E8;">.</span><span style="color:#79B8FF;">1</span><span style="color:#F97583;">-</span><span style="color:#E1E4E8;">linux</span><span style="color:#F97583;">-</span><span style="color:#E1E4E8;">x86_64.tar.gz </span><span style="color:#F97583;">-</span><span style="color:#79B8FF;">C</span><span style="color:#E1E4E8;"> </span><span style="color:#F97583;">/</span><span style="color:#E1E4E8;">usr</span><span style="color:#F97583;">/</span><span style="color:#E1E4E8;">local</span></span>
<span class="line"><span style="color:#E1E4E8;">[root</span><span style="color:#F97583;">@server</span><span style="color:#E1E4E8;">1 </span><span style="color:#F97583;">~</span><span style="color:#E1E4E8;">]# mv </span><span style="color:#F97583;">/</span><span style="color:#E1E4E8;">usr</span><span style="color:#F97583;">/</span><span style="color:#E1E4E8;">local</span><span style="color:#F97583;">/</span><span style="color:#E1E4E8;">kibana</span><span style="color:#F97583;">-</span><span style="color:#79B8FF;">7.7</span><span style="color:#E1E4E8;">.</span><span style="color:#79B8FF;">1</span><span style="color:#F97583;">-</span><span style="color:#E1E4E8;">linux</span><span style="color:#F97583;">-</span><span style="color:#E1E4E8;">x86_64  </span><span style="color:#F97583;">/</span><span style="color:#E1E4E8;">usr</span><span style="color:#F97583;">/</span><span style="color:#E1E4E8;">local</span><span style="color:#F97583;">/</span><span style="color:#E1E4E8;">kibana</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292E;">[root</span><span style="color:#D73A49;">@server</span><span style="color:#24292E;">1 </span><span style="color:#D73A49;">~</span><span style="color:#24292E;">]# tar </span><span style="color:#D73A49;">-</span><span style="color:#24292E;">zxvf kibana</span><span style="color:#D73A49;">-</span><span style="color:#005CC5;">7.7</span><span style="color:#24292E;">.</span><span style="color:#005CC5;">1</span><span style="color:#D73A49;">-</span><span style="color:#24292E;">linux</span><span style="color:#D73A49;">-</span><span style="color:#24292E;">x86_64.tar.gz </span><span style="color:#D73A49;">-</span><span style="color:#005CC5;">C</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">/</span><span style="color:#24292E;">usr</span><span style="color:#D73A49;">/</span><span style="color:#24292E;">local</span></span>
<span class="line"><span style="color:#24292E;">[root</span><span style="color:#D73A49;">@server</span><span style="color:#24292E;">1 </span><span style="color:#D73A49;">~</span><span style="color:#24292E;">]# mv </span><span style="color:#D73A49;">/</span><span style="color:#24292E;">usr</span><span style="color:#D73A49;">/</span><span style="color:#24292E;">local</span><span style="color:#D73A49;">/</span><span style="color:#24292E;">kibana</span><span style="color:#D73A49;">-</span><span style="color:#005CC5;">7.7</span><span style="color:#24292E;">.</span><span style="color:#005CC5;">1</span><span style="color:#D73A49;">-</span><span style="color:#24292E;">linux</span><span style="color:#D73A49;">-</span><span style="color:#24292E;">x86_64  </span><span style="color:#D73A49;">/</span><span style="color:#24292E;">usr</span><span style="color:#D73A49;">/</span><span style="color:#24292E;">local</span><span style="color:#D73A49;">/</span><span style="color:#24292E;">kibana</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>这里我们将 Kibana 安装到了 /usr/local 目录下。</p><p><strong>（2）配置 Kibana</strong></p><p>由于将 Kibana 安装到了 /usr/local 目录下，因此，Kibana 的配置文件为 /usr/local/kibana/config/kibana.yml，其配置非常简单，这里仅列出常用的配置项，内容如下：</p><div class="language-java vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">java</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#E1E4E8;">server.port</span><span style="color:#F97583;">:</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">5601</span></span>
<span class="line"><span style="color:#E1E4E8;">server.host</span><span style="color:#F97583;">:</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">&quot;172.16.213.152&quot;</span></span>
<span class="line"><span style="color:#E1E4E8;">elasticsearch.url</span><span style="color:#F97583;">:</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">&quot;http://172.16.213.138:9200&quot;</span></span>
<span class="line"><span style="color:#E1E4E8;">kibana.index</span><span style="color:#F97583;">:</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">&quot;.kibana&quot;</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292E;">server.port</span><span style="color:#D73A49;">:</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">5601</span></span>
<span class="line"><span style="color:#24292E;">server.host</span><span style="color:#D73A49;">:</span><span style="color:#24292E;"> </span><span style="color:#032F62;">&quot;172.16.213.152&quot;</span></span>
<span class="line"><span style="color:#24292E;">elasticsearch.url</span><span style="color:#D73A49;">:</span><span style="color:#24292E;"> </span><span style="color:#032F62;">&quot;http://172.16.213.138:9200&quot;</span></span>
<span class="line"><span style="color:#24292E;">kibana.index</span><span style="color:#D73A49;">:</span><span style="color:#24292E;"> </span><span style="color:#032F62;">&quot;.kibana&quot;</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>其中，每个配置项的含义介绍如下：</p><ul><li><p><strong>server.port</strong>，Kibana 绑定的监听端口，默认是 5601；</p></li><li><p><strong>server.host</strong>，Kibana 绑定的 IP 地址，如果内网访问，设置为内网地址即可；</p></li><li><p><strong>elasticsearch.url</strong>，Kibana 访问 Elasticsearch 的地址，如果是 Elasticsearch 集群，添加任一集群节点 IP 即可，官方推荐设置为 Elasticsearch 集群中 client node 角色的节点 IP；</p></li><li><p><strong>kibana.index</strong>，用于存储 Kibana 数据信息的索引，这个可以在 Kibana Web 界面中看到。</p></li></ul><p>注意，这里我配置了 Kibana 从 172.16.213.138 节点上获取 Elasticsearch 数据，因此需要在此节点的 Elasticsearch 配置文件中添加如下内容：</p><div class="language-java vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">java</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#E1E4E8;">http.cors.enabled</span><span style="color:#F97583;">:</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">true</span></span>
<span class="line"><span style="color:#E1E4E8;">http.cors.allow</span><span style="color:#F97583;">-</span><span style="color:#E1E4E8;">origin</span><span style="color:#F97583;">:</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">&quot;*&quot;</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292E;">http.cors.enabled</span><span style="color:#D73A49;">:</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">true</span></span>
<span class="line"><span style="color:#24292E;">http.cors.allow</span><span style="color:#D73A49;">-</span><span style="color:#24292E;">origin</span><span style="color:#D73A49;">:</span><span style="color:#24292E;"> </span><span style="color:#032F62;">&quot;*&quot;</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>其中，http.cors.enabled 用来设置是否支持跨域，默认为 false，这里设置为 true。当设置为允许跨域时，http.cors.allow-origin 设置才能生效，此配置默认值为 *，表示支持所有域名；如果只允许某些域名能访问，那么可以使用正则表达式匹配相关域名即可。</p><p><strong>（3）启动 Kibana 服务</strong></p><p>所有配置完成后，就可以启动 Kibana 了，启动的命令在 /usr/local/kibana/bin 目录下，具体如下：</p><div class="language-dart vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">dart</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#E1E4E8;">[root</span><span style="color:#F97583;">@server</span><span style="color:#E1E4E8;">1 </span><span style="color:#F97583;">~</span><span style="color:#E1E4E8;">]# cd </span><span style="color:#F97583;">/</span><span style="color:#E1E4E8;">usr</span><span style="color:#F97583;">/</span><span style="color:#E1E4E8;">local</span><span style="color:#F97583;">/</span><span style="color:#E1E4E8;">kibana</span><span style="color:#F97583;">/</span></span>
<span class="line"><span style="color:#E1E4E8;">[root</span><span style="color:#F97583;">@server</span><span style="color:#E1E4E8;">1 kibana]# nohup bin</span><span style="color:#F97583;">/</span><span style="color:#E1E4E8;">kibana  </span><span style="color:#F97583;">--</span><span style="color:#E1E4E8;">allow</span><span style="color:#F97583;">-</span><span style="color:#E1E4E8;">root </span><span style="color:#F97583;">&amp;</span></span>
<span class="line"><span style="color:#E1E4E8;">[root</span><span style="color:#F97583;">@server</span><span style="color:#E1E4E8;">1 kibana]# ps </span><span style="color:#F97583;">-</span><span style="color:#E1E4E8;">ef</span><span style="color:#F97583;">|</span><span style="color:#E1E4E8;">grep node</span></span>
<span class="line"><span style="color:#E1E4E8;">root      </span><span style="color:#79B8FF;">6407</span><span style="color:#E1E4E8;">     </span><span style="color:#79B8FF;">1</span><span style="color:#E1E4E8;">  </span><span style="color:#79B8FF;">0</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">Jan15</span><span style="color:#E1E4E8;"> </span><span style="color:#F97583;">?</span><span style="color:#E1E4E8;">        </span><span style="color:#79B8FF;">00</span><span style="color:#F97583;">:</span><span style="color:#79B8FF;">59</span><span style="color:#F97583;">:</span><span style="color:#79B8FF;">11</span><span style="color:#E1E4E8;"> bin</span><span style="color:#F97583;">/</span><span style="color:#E1E4E8;">..</span><span style="color:#F97583;">/</span><span style="color:#E1E4E8;">node</span><span style="color:#F97583;">/</span><span style="color:#E1E4E8;">bin</span><span style="color:#F97583;">/</span><span style="color:#E1E4E8;">node </span><span style="color:#F97583;">--</span><span style="color:#E1E4E8;">no</span><span style="color:#F97583;">-</span><span style="color:#E1E4E8;">warnings bin</span><span style="color:#F97583;">/</span><span style="color:#E1E4E8;">..</span><span style="color:#F97583;">/</span><span style="color:#E1E4E8;">src</span><span style="color:#F97583;">/</span><span style="color:#E1E4E8;">cli</span></span>
<span class="line"><span style="color:#E1E4E8;">root      </span><span style="color:#79B8FF;">7732</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">32678</span><span style="color:#E1E4E8;">  </span><span style="color:#79B8FF;">0</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">15</span><span style="color:#F97583;">:</span><span style="color:#79B8FF;">13</span><span style="color:#E1E4E8;"> pts</span><span style="color:#F97583;">/</span><span style="color:#79B8FF;">0</span><span style="color:#E1E4E8;">    </span><span style="color:#79B8FF;">00</span><span style="color:#F97583;">:</span><span style="color:#79B8FF;">00</span><span style="color:#F97583;">:</span><span style="color:#79B8FF;">00</span><span style="color:#E1E4E8;"> grep </span><span style="color:#F97583;">--</span><span style="color:#E1E4E8;">color</span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;">auto node</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292E;">[root</span><span style="color:#D73A49;">@server</span><span style="color:#24292E;">1 </span><span style="color:#D73A49;">~</span><span style="color:#24292E;">]# cd </span><span style="color:#D73A49;">/</span><span style="color:#24292E;">usr</span><span style="color:#D73A49;">/</span><span style="color:#24292E;">local</span><span style="color:#D73A49;">/</span><span style="color:#24292E;">kibana</span><span style="color:#D73A49;">/</span></span>
<span class="line"><span style="color:#24292E;">[root</span><span style="color:#D73A49;">@server</span><span style="color:#24292E;">1 kibana]# nohup bin</span><span style="color:#D73A49;">/</span><span style="color:#24292E;">kibana  </span><span style="color:#D73A49;">--</span><span style="color:#24292E;">allow</span><span style="color:#D73A49;">-</span><span style="color:#24292E;">root </span><span style="color:#D73A49;">&amp;</span></span>
<span class="line"><span style="color:#24292E;">[root</span><span style="color:#D73A49;">@server</span><span style="color:#24292E;">1 kibana]# ps </span><span style="color:#D73A49;">-</span><span style="color:#24292E;">ef</span><span style="color:#D73A49;">|</span><span style="color:#24292E;">grep node</span></span>
<span class="line"><span style="color:#24292E;">root      </span><span style="color:#005CC5;">6407</span><span style="color:#24292E;">     </span><span style="color:#005CC5;">1</span><span style="color:#24292E;">  </span><span style="color:#005CC5;">0</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">Jan15</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">?</span><span style="color:#24292E;">        </span><span style="color:#005CC5;">00</span><span style="color:#D73A49;">:</span><span style="color:#005CC5;">59</span><span style="color:#D73A49;">:</span><span style="color:#005CC5;">11</span><span style="color:#24292E;"> bin</span><span style="color:#D73A49;">/</span><span style="color:#24292E;">..</span><span style="color:#D73A49;">/</span><span style="color:#24292E;">node</span><span style="color:#D73A49;">/</span><span style="color:#24292E;">bin</span><span style="color:#D73A49;">/</span><span style="color:#24292E;">node </span><span style="color:#D73A49;">--</span><span style="color:#24292E;">no</span><span style="color:#D73A49;">-</span><span style="color:#24292E;">warnings bin</span><span style="color:#D73A49;">/</span><span style="color:#24292E;">..</span><span style="color:#D73A49;">/</span><span style="color:#24292E;">src</span><span style="color:#D73A49;">/</span><span style="color:#24292E;">cli</span></span>
<span class="line"><span style="color:#24292E;">root      </span><span style="color:#005CC5;">7732</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">32678</span><span style="color:#24292E;">  </span><span style="color:#005CC5;">0</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">15</span><span style="color:#D73A49;">:</span><span style="color:#005CC5;">13</span><span style="color:#24292E;"> pts</span><span style="color:#D73A49;">/</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">    </span><span style="color:#005CC5;">00</span><span style="color:#D73A49;">:</span><span style="color:#005CC5;">00</span><span style="color:#D73A49;">:</span><span style="color:#005CC5;">00</span><span style="color:#24292E;"> grep </span><span style="color:#D73A49;">--</span><span style="color:#24292E;">color</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">auto node</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><p>这样，Kibana 对应的 Node 服务就启动起来了。</p><p><strong>（4）配置 Kibana 展示 Elasticsearch 数据</strong></p><p>继续接着 EFLK 架构进行介绍，Filebeat 从 Nginx 上收集数据到 Kafka，然后 Logstash 从 Kafka 中拉取数据。如果数据能够正确发送到 Elasticsearch，我们就可以在 Kibana 中配置索引了。</p><p>登录 Kibana，打开浏览器访问 <a href="http://172.16.213.152:5601" target="_blank" rel="noreferrer">http://172.16.213.152:5601</a>，会自动打开 Kibana 的 Web 界面。在登录 Kibana 后，第一步要做的是配置 index_pattern，点击 Kibana 左侧导航中的 Management 菜单，然后选择右侧的 Index Patterns 按钮，如下图所示：</p><p><img src="https://s0.lgstatic.com/i/image/M00/2D/3E/CgqCHl8C6eOAdnuxAAFsrmWOu4w817.png" alt="Drawing 2.png"></p><p>接着，点击 Index Patterns 按钮，开始创建一个 index pattern，如下图所示：</p><p><img src="https://s0.lgstatic.com/i/image/M00/2D/3E/CgqCHl8C6eqAAgLKAADsPr8crdw196.png" alt="Drawing 3.png"></p><p>点击上图右上角的 Create index pattern 按钮，创建 index pattern 的界面如下所示：</p><p><img src="https://s0.lgstatic.com/i/image/M00/2D/3E/CgqCHl8C6fKANkWEAAFP5kYzi14872.png" alt="Drawing 4.png"></p><p>这里需要填写一个 Index pattern 名称，这个 Index pattern，其实我已经在 Logstash 中定义好了，名为 nginxlogs-%{+YYYY.MM.dd}，而这里只需填入 nginxlogs-* 即可。如果已经有对应的数据写入 Elasticsearch，那么 Kibana 会自动检测到并抓取映射文件，此时就可以创建 Index pattern 了，如上图所示。如果你填入索引名称后，右边的 &quot;Next step&quot; 按钮仍然是不可点击状态的，则说明 Kibana 还没有抓取到输入索引对应的映射文件，此时可以让 Filebeat 再生成一点数据，只要数据正常传到 Elasticsearch 中，那么 Kibana 就能马上检测到。</p><p>接着，选择日志按照时间字段 &quot;@timestamp&quot; 进行排序，如下图所示：</p><p><img src="https://s0.lgstatic.com/i/image/M00/2D/33/Ciqc1F8C6fiAPIYqAAFtNHZYRGg459.png" alt="Drawing 5.png"></p><p>最后，点击 &quot;Create index pattern&quot; 按钮，完成 Index pattern 的创建，如下图所示：</p><p><img src="https://s0.lgstatic.com/i/image/M00/2D/3E/CgqCHl8C6f-ANFKgAAGQU0G9UVM669.png" alt="Drawing 6.png"></p><p>创建完成 Index pattern 后，点击 kibana 左侧导航中的 Discover 导航栏，即可展示已经收集到的日志信息，如下图所示：</p><p><img src="https://s0.lgstatic.com/i/image/M00/2D/3E/CgqCHl8C6gqALoBmAAKJSgpPHmE324.png" alt="Drawing 7.png"></p><p>Kibana 的 Web 界面操作和使用比较简单，这里仅仅介绍下左侧导航栏中几个常用导航的含义及功能，更细节的功能可自行操作几遍就基本掌握了。</p><ul><li><p>Discover：主要用来进行日志检索、查询数据，这个功能使用最多。</p></li><li><p>Visualize：数据可视化，可以在这里创建各种维度的可视化视图，如面积图、折线图、饼图、热力图、标签云等，通过创建可视化视图，日志数据浏览会变得非常直观。</p></li><li><p>Dashboard：仪表盘功能，仪表盘其实是可视化视图的组合，通过将各种可视化视图组合到一个页面，就可以从整体上了解数据和日志的各种状态。</p></li><li><p>Dev Tools：这是一个调试工具控制台，Kibana 提供了一个 UI 来与 Elasticsearch 的 REST API 进行交互。 控制台主要有两个方面，即 Editor（编辑器）与 Response（响应），Editor 用来编写对 Elasticsearch 的请求，Response 显示对请求的响应。</p></li><li><p>Management：这是管理界面，可以在这里创建索引模式，调整 Kibana 设置等操作。</p></li></ul><p>至此，ELK 收集 Nginx 日志的配置工作完成。</p><h3 id="总结" tabindex="-1">总结 <a class="header-anchor" href="#总结" aria-label="Permalink to &quot;总结&quot;">​</a></h3><p>本课时主要介绍了生产环境下的 EFLK 应用架构收集 Nginx 日志的应用案例。首先讲解了 Nginx 日志如何进行字段分割，然后介绍了如何通过 Filebeat 收集 Nginx 日志并传送到 Kafka 集群中，接着介绍了如何通过 Logstash 从 Kafka 中消费日志，并将日志进行字段分割，同时传送到 Elasticsearch 中进行存储和查询，最后介绍了如何在 Kibana 中展示日志和查询日志。</p>`,90),e=[o];function t(r,c,y,E,i,d){return a(),n("div",null,e)}const b=s(p,[["render",t]]);export{g as __pageData,b as default};
