import{_ as o,j as e,o as t,g as c,k as n,h as s,Q as p,s as l}from"./chunks/framework.a0d18f64.js";const D=JSON.parse('{"title":"第16讲：轻量级日志收集工具Filebeat应用案例","description":"","frontmatter":{},"headers":[],"relativePath":"posts/devops/042_大数据运维实战/(3087) 第16讲：轻量级日志收集工具 Filebeat 应用案例.md","filePath":"posts/devops/042_大数据运维实战/(3087) 第16讲：轻量级日志收集工具 Filebeat 应用案例.md","lastUpdated":1696682708000}'),r={name:"posts/devops/042_大数据运维实战/(3087) 第16讲：轻量级日志收集工具 Filebeat 应用案例.md"},E=p("",5),y=p("",14),i=p("",25),u=l("p",null,"可以看到，Filebeat 已经将收集到的数据传到了 Redis 服务器上。",-1),F=l("h3",{id:"总结",tabindex:"-1"},[s("总结 "),l("a",{class:"header-anchor",href:"#总结","aria-label":'Permalink to "总结"'},"​")],-1),q=l("p",null,"本课时主要讲解了 Filebeat 的安装、配置及如何使用。在经典的 EFK 架构中，Filebeat 经常作为前端收集日志，然后将日志传给 Kafka，然后 Logstash 再从 Kafka 消费日志中将数据发送到 Elasticsearch 中，最后在 Kibana 中进行可视化展示。在后面的课时内容中我将陆续介绍这些架构的实现细节。",-1);function d(b,g,h,A,f,C){const a=e("Image");return t(),c("div",null,[E,n(a,{alt:"image1.png",src:"https://s0.lgstatic.com/i/image/M00/22/B4/Ciqc1F7saKKAQ8YZAAEBev585Hk521.png"}),s(),y,n(a,{alt:"01.png",src:"https://s0.lgstatic.com/i/image/M00/22/B5/Ciqc1F7sakCAZRRhAAVtPJ5WfBg187.png"}),s(),n(a,{alt:"02.png",src:"https://s0.lgstatic.com/i/image/M00/22/B5/Ciqc1F7sakqAYIedAAU0BudFkBA057.png"}),s(),n(a,{alt:"03.png",src:"https://s0.lgstatic.com/i/image/M00/22/C1/CgqCHl7salKAH_SMAAb9p7oShcE030.png"}),s(),i,n(a,{alt:"image2.png",src:"https://s0.lgstatic.com/i/image/M00/22/B6/Ciqc1F7saviAIgKIAACKia52tP0739.png"}),s(),u,F,q])}const m=o(r,[["render",d]]);export{D as __pageData,m as default};
